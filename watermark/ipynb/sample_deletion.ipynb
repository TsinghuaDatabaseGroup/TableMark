{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "pd.options.display.max_rows = 120\n",
    "pd.options.display.max_columns = 75\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "def filter(df: pd.DataFrame, col: str, values: list[float], tol: float = 1e-6) -> pd.DataFrame:\n",
    "  def is_within_tolerance(val, target_values, tolerance):\n",
    "    return any(abs(val - target) < tolerance for target in target_values)\n",
    "  \n",
    "  filtered_df = df[df[col].apply(lambda x: is_within_tolerance(x, values, tol))]\n",
    "  return filtered_df\n",
    "\n",
    "sample_deletion_ratios = [0.1]\n",
    "\n",
    "df_ours = pd.read_json('../results_final/sample_deletion.json', lines=True)\n",
    "df_ours = filter(df_ours, 'sample_deletion_ratio', sample_deletion_ratios)\n",
    "\n",
    "all_datanames = [\n",
    "  'beijing',\n",
    "  'default',\n",
    "  'phishing',\n",
    "  'shoppers',\n",
    "]\n",
    "all_num_users = [\n",
    "  1000,\n",
    "]\n",
    "all_watermark = [\n",
    "  'pair_compare_one_pair',\n",
    "]\n",
    "all_num_classes = [\n",
    "  256,\n",
    "]\n",
    "all_num_watermark_bits = [\n",
    "  32,\n",
    "]\n",
    "all_min_hamming_dist = [\n",
    "  7,\n",
    "]\n",
    "all_ratio_num_samples_per_class_interval = [\n",
    "  -30000,\n",
    "]\n",
    "all_quality_loss = [\n",
    "  'quad_random_init985',\n",
    "]\n",
    "all_embedding_models = [\n",
    "  'orig',\n",
    "]\n",
    "all_quality_modes = [\n",
    "  'average',\n",
    "]\n",
    "all_gen_code_losses = [\n",
    "  'general_bfs',\n",
    "]\n",
    "all_tao_approximations = [\n",
    "  0\n",
    "]\n",
    "all_time_limits = [\n",
    "  180\n",
    "]\n",
    "all_error_rates = [\n",
    "  0.001,\n",
    "]\n",
    "all_deletion_rates = [\n",
    "  0.1,\n",
    "]\n",
    "all_dim_ratios = [\n",
    "  'correct-pca-0.99',\n",
    "]\n",
    "all_upper_bounds = [\n",
    "  '6stage_splus-0.01-0.01',\n",
    "]\n",
    "df_ours = df_ours[['dataname', 'num_users', 'watermark', 'num_classes', 'num_samples', 'num_watermark_bits', 'min_hamming_dist', 'ratio_num_samples_per_class_interval', 'classifier', 'quality_loss', 'embedding_model', 'correct', 'tao_approximation', 'num_tested_samples_per_class', 'loss', 'quad_loss', 'time_limit', 'min_gap', 'error_rate', 'gap', 'deletion_rate', 'sample_deletion_ratio', 'dim_ratio', 'num_samples_per_class_upper_bound', 'gen_code_loss', 'gauss', 'alter']]\n",
    "df_ours['embedding_model'] = df_ours['embedding_model'].apply(lambda x: x[:4])\n",
    "df_ours = df_ours[df_ours['embedding_model'].isin(all_embedding_models)]\n",
    "df_ours = df_ours[df_ours['time_limit'].isin(all_time_limits)]\n",
    "df_ours = df_ours[df_ours['dataname'].isin(all_datanames)]\n",
    "df_ours = df_ours[df_ours['num_users'].isin(all_num_users)]\n",
    "df_ours = df_ours[df_ours['watermark'].isin(all_watermark)]\n",
    "df_ours = df_ours[df_ours['num_classes'].isin(all_num_classes)]\n",
    "df_ours = df_ours[df_ours['num_watermark_bits'].isin(all_num_watermark_bits)]\n",
    "df_ours = df_ours[df_ours['num_samples'] < 50000]\n",
    "df_ours = df_ours[df_ours['min_hamming_dist'].isin(all_min_hamming_dist)]\n",
    "df_ours = df_ours[df_ours['ratio_num_samples_per_class_interval'].isin(all_ratio_num_samples_per_class_interval)]\n",
    "df_ours = df_ours[df_ours['tao_approximation'].isin(all_tao_approximations)]\n",
    "df_ours = df_ours[df_ours['error_rate'].isin(all_error_rates)]\n",
    "df_ours = df_ours[df_ours['classifier'] == 'nn']\n",
    "df_ours = df_ours[df_ours['deletion_rate'].isin(all_deletion_rates)]\n",
    "df_ours = df_ours[df_ours['quality_loss'].isin(all_quality_loss)]\n",
    "df_ours = df_ours[df_ours['dim_ratio'].isin(all_dim_ratios)]\n",
    "df_ours = df_ours[df_ours['num_samples_per_class_upper_bound'].isin(all_upper_bounds)]\n",
    "df_ours = df_ours[df_ours['gen_code_loss'].isin(all_gen_code_losses)]\n",
    "df_ours = df_ours[df_ours['deletion_rate'] == 0.1]\n",
    "df_ours = df_ours[df_ours['gauss'] == 0.01]\n",
    "df_ours = df_ours[df_ours['alter'] == 0.01]\n",
    "df_ours = df_ours.rename(columns={\n",
    "  'ratio_num_samples_per_class_interval': 'ratio',\n",
    "  'num_watermark_bits': 'bits',\n",
    "  'min_hamming_dist': 'hamming_distance'\n",
    "})\n",
    "\n",
    "df_ours = df_ours.groupby(by=['num_users', 'bits', 'hamming_distance', 'ratio', 'dataname', 'sample_deletion_ratio', 'error_rate', 'deletion_rate', 'gauss', 'alter'], as_index=False).head(100).groupby(by=['num_users', 'bits', 'hamming_distance', 'ratio', 'dataname', 'sample_deletion_ratio', 'error_rate', 'deletion_rate', 'gauss', 'alter'], as_index=False)[['correct']].agg({\n",
    "  'correct': ['count', 'mean'],\n",
    "})\n",
    "for col in df_ours.columns:\n",
    "  if df_ours[col].dtype in [np.float32, np.float64, float]:\n",
    "    df_ours[col] = df_ours[col].round(3)\n",
    "# df_ours = df_ours.reset_index(drop=True)\n",
    "\n",
    "dataname2btz = {\n",
    "  'beijing': (5, 0, 53),\n",
    "  'default': (5, 0, 53),\n",
    "  'shoppers': (5, 0, 7),\n",
    "}\n",
    "\n",
    "df_freqwm = pd.read_json('../results_final/freqwm_sample_deletion.json', lines=True)\n",
    "df_freqwm = df_freqwm[df_freqwm['t'] == 'dyn']\n",
    "df_freqwm['sample_deletion_ratio'] = df_freqwm['sample_deletion_ratio'].round(3)\n",
    "df_freqwm = filter(df_freqwm, 'sample_deletion_ratio', sample_deletion_ratios)\n",
    "df_freqwm = df_freqwm.groupby(['dataname', 'num_watermark_bits', 'sample_deletion_ratio'], as_index=False).head(100).groupby(['dataname', 'num_watermark_bits', 'sample_deletion_ratio'], as_index=False)[['correct']].agg({\n",
    "  'correct': ['count', 'mean'],\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "df_tabular_mark = pd.read_json('../results_final/tabular_mark_sample_deletion.json', lines=True)\n",
    "df_tabular_mark = df_tabular_mark[df_tabular_mark['num_cells_ratio'] == 0.15]\n",
    "df_tabular_mark = df_tabular_mark[df_tabular_mark['p_ratio'] == 0.2]\n",
    "df_tabular_mark = df_tabular_mark[df_tabular_mark['num_units'] == 2]\n",
    "df_tabular_mark['sample_deletion_ratio'] = df_tabular_mark['sample_deletion_ratio'].round(3)\n",
    "df_tabular_mark = filter(df_tabular_mark, 'sample_deletion_ratio', sample_deletion_ratios)\n",
    "df_tabular_mark = df_tabular_mark.groupby(['dataname', 'num_watermark_bits', 'sample_deletion_ratio'], as_index=True).head(100).groupby(['dataname', 'num_watermark_bits', 'sample_deletion_ratio'], as_index=True)[['correct']].agg({\n",
    "  'correct': ['count', 'mean'],\n",
    "})\n",
    "\n",
    "df_tabwak_partition = pd.read_json('../results_final/tabwak_partition_sample_deletion.json', lines=True)\n",
    "df_tabwak_partition = df_tabwak_partition[(df_tabwak_partition['token_dim'] == 5) | (df_tabwak_partition['token_dim'] == 6) | (df_tabwak_partition['dataname'].isin(['default', 'phishing', 'shoppers']))]\n",
    "df_tabwak_partition['sample_deletion_ratio'] = df_tabwak_partition['sample_deletion_ratio'].round(3)\n",
    "df_tabwak_partition = filter(df_tabwak_partition, 'sample_deletion_ratio', sample_deletion_ratios)\n",
    "df_tabwak_partition = df_tabwak_partition.groupby(['dataname', 'num_watermark_bits', 'sample_deletion_ratio'], as_index=False).head(100).groupby(['dataname', 'num_watermark_bits', 'sample_deletion_ratio'], as_index=False)[['correct']].agg({\n",
    "  'correct': ['count', 'mean'],\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "display('TableMark', df_ours)\n",
    "display('FreqyWM', df_freqwm)\n",
    "display('TabularMark', df_tabular_mark)\n",
    "display('TabWak Partition', df_tabwak_partition)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabsyn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
